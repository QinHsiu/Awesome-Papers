- 论文
  - [A Survey on Generative Diffusion Model](https://arxiv.org/abs/2209.02646)
  - [Self-Supervised Multimodal Learning: A Survey](https://arxiv.org/abs/2304.01008)
    
    

  - Sound and Visual Representation Learning with Multiple Pretraining Tasks Arxiv2022 [Paper](https://arxiv.org/abs/2201.01046) [Note](https://juejin.cn/post/7080724955414921247)

  - Interventional Contrastive Learning with Meta Semantic Regularizer ICML2022 [Paper](https://arxiv.org/abs/2206.14702) [Note](https://juejin.cn/post/7183909795198402619)

  - MetAug: Contrastive Learning via Meta Feature Augmentation ICML2022 [Paper](https://arxiv.org/abs/2203.05119) [Note](https://juejin.cn/post/7182797568681148477)

  - Automated Self-Supervised Learning for Graphs ICLR2022 [Paper](https://arxiv.org/abs/2106.05470) [Note](https://juejin.cn/post/7081164839837499399)

  - Neighbor Contrastive Learning on Learnable Graph Augmentation AAAI2023 [Paper](https://arxiv.org/abs/2301.01404) [Note](https://juejin.cn/post/7222174980531191845)

  - [[DCL][NeurIPS 20]Debiased Contrastive Learning](https://proceedings.neurips.cc/paper/2020/hash/63c3ddcc7b23daa1e42dc41f9a44a873-Abstract.html)

  - [[ALBEF][NeurIPS 21]Align before Fuse: Vision and Language Representation Learning with Momentum Distillation](https://arxiv.org/abs/2107.07651)
  - [[Rethink Trm][ICML 21]Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)
  - [[DynamicVit][NeurIPS 21]DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification](https://proceedings.neurips.cc/paper/2021/hash/747d3443e319a22747fbb873e8b2f9f2-Abstract.html)
  - [[CL][CVPR 21]Understanding the Behaviour of Contrastive Loss](https://arxiv.org/abs/2012.09740)
  - [[Co2][ICLR 21]CO2: Consistent Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2010.02217)
  - 

  - [[FFCLIP][NeurIPS 22]One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations](https://arxiv.org/abs/2210.07883)
  - [[CFViT][AAAI 22]CF-ViT: A General Coarse-to-Fine Method for Vision Transformer](https://arxiv.org/abs/2203.03821)
  - [[SPACH][AAAI 22]When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism](https://arxiv.org/abs/2201.10801)
  - [[CLCLEF][ACL 22]GL-CLEF: A Global–Local Contrastive Learning Framework for Cross-lingual Spoken Language Understanding](https://arxiv.org/abs/2204.08325)
  - [[MixSKD][ECCV 22]MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition](https://arxiv.org/abs/2208.05768)
  - [[IPMT][NeurIPS 22]Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2210.06780)
  - [[Trm后剪枝][NeurIPS 22]A Fast Post-Training Pruning Framework for Transformers](https://arxiv.org/abs/2204.09656)
  - [[DataDistill][NeurIPS 22]Dataset Distillation via Factorization](https://arxiv.org/abs/2210.16774)
  - [[RVSA][TGRS 22]Advancing Plain Vision Transformer Towards Remote Sensing Foundation Model](https://arxiv.org/abs/2208.03987)
  - [[OnDeviceTraining][NeurIPS 22]On-Device Training Under 256KB Memory](https://arxiv.org/abs/2206.15472)
  - [[ColloSSL][IMWUT 22]ColloSSL: Collaborative Self-Supervised Learning for Human Activity Recognition](https://arxiv.org/abs/2202.00758)
  - [[TriBYOL][ICASSP 22]TriBYOL: Triplet BYOL for Self-Supervised Representation Learning](https://arxiv.org/abs/2206.03012)
  - [[LoRoT][ECCV 22]Tailoring Self-Supervision for Supervised Learning](https://arxiv.org/abs/2207.10023)
  - [[MakeFeat][CVPR 22]Masked Feature Prediction for Self-Supervised Visual Pre-Training](https://arxiv.org/abs/2112.09133)
  - [[VICReg][ICLR 22]VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning](https://arxiv.org/abs/2105.04906)
  - [[RoSA][IJCAI 22]RoSA: A Robust Self-Aligned Framework for Node-Node Graph Contrastive Learning](https://arxiv.org/abs/2204.13846)
  - [[X-CLIP][MM 22]X-CLIP: End-to-End Multi-grained Contrastive Learning for Video-Text Retrieval](https://arxiv.org/abs/2207.07285)
  - [[GAME][NeurIPS 22]Revisiting Graph Contrastive Learning from the Perspective of Graph Spectrum](https://arxiv.org/abs/2210.02330)
  - 

  - [[FasterVit][Techport]FasterViT: Fast Vision Transformers with Hierarchical Attention](https://arxiv.org/abs/2306.06189)
  - [[BLIP][Arxiv 23]InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/abs/2305.06500)
  - [[ControlVideo][Arxiv 23]ControlVideo: Training-free Controllable Text-to-Video Generation](https://arxiv.org/abs/2305.13077)
  - [[IRB][Arxiv 23]Rethinking Mobile Block for Efficient Neural Models](https://arxiv.org/abs/2301.01146)
  - [[VideoMAE][Arxiv 23]VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking](https://arxiv.org/abs/2303.16727)
  - [[INSTRUCTEVAL][Arxiv 23]INSTRUCTEVAL: Towards Holistic Evaluation of Instruction-Tuned Large Language Models](https://arxiv.org/abs/2306.04757)
  - [[I-JEPA][ICCV 23]Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture](https://arxiv.org/abs/2301.08243)
  - [[TryOnDiffusion][CVPR 23]TryOnDiffusion: A Tale of Two UNets](https://arxiv.org/abs/2306.08276)
  - [[SDT][CVPR 23]Disentangling Writer and Character Styles for Handwriting Generation](https://arxiv.org/abs/2303.14736)
  - [[DETR][CVPR 23]Siamese DETR](https://arxiv.org/abs/2303.18144)
  - [[DataGenerate][Arxiv 23]Regeneration Learning: A Learning Paradigm for Data Generation](https://arxiv.org/abs/2301.08846)
  - [[Dropout][ICML 23]Dropout Reduces Underfitting](https://arxiv.org/abs/2303.01500)
  - [[advDM][ICML 23]Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples](https://arxiv.org/abs/2302.04578)
  - [[HomoDitill][Arxiv 23]HOMODISTIL: HOMOTOPIC TASK-AGNOSTIC DISTIL- LATION OF PRE-TRAINED TRANSFORMERS](https://arxiv.org/abs/2302.09632)
  - [[GWAE][ICLR 23]GROMOV-WASSERSTEIN AUTOENCODERS](https://arxiv.org/abs/2209.07007)
  - [[MLPinit][ICLR 23]MLPINIT: EMBARRASSINGLY SIMPLE GNN TRAIN- ING ACCELERATION WITH MLP INITIALIZATION](https://arxiv.org/abs/2210.00102)
  - [[Distill GNN][WSDM  23]Learning to Distill Graph Neural Networks](http://shichuan.org/doc/144.pdf)
  - [[Unidiffuser][ICML 23]One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale](https://arxiv.org/abs/2303.06555)

- Mixup
  - [[MixUP][ICLR 18]mixup: BEYOND EMPIRICAL RISK MINIMIZATION](https://arxiv.org/abs/1710.09412)
  - [[CutMix][ICCV 19]CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features](https://arxiv.org/abs/1905.04899)
  - [[MainfoldMixup][ICML 19]Manifold Mixup: Better Representations by Interpolating Hidden States](https://arxiv.org/abs/1806.05236)
  - [[CoMixup][ICLR 21]Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity](https://arxiv.org/abs/2102.03065)
  - [[SaliencyMix][ICLR 21]SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization](https://arxiv.org/abs/2006.01791)
  - [[StyleMix][CVPR 21]StyleMix: Separating Content and Style for Enhanced Data Augmentation](https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.pdf)
  - [[SuperMix][CVPR 21]SuperMix: Supervising the Mixing Data Augmentation](https://arxiv.org/abs/2003.05034)
  - [[AlignMixup][CVPR 22]AlignMix: Improving representation by interpolating aligned features](https://arxiv.org/abs/2103.15375)
  - [[TokenMixup][NeurIPS 22]TokenMixup: Efficient Attention-guided Token-level Data Augmentation for Transformers](https://arxiv.org/abs/2210.07562)
    
- 解读
  - [2022-top10自监督论文](https://mp.weixin.qq.com/s/AQIWt4deRGnRw3E6msRrig)
  - [IPMT-NeurIPS2022](https://mp.weixin.qq.com/s/y9jKTWi6NTNe_-IhaxE6Mg)
  - [VideMAE-NeurIPS2022](https://mp.weixin.qq.com/s/vrRrOFWHYWbjvFDvt5Bu7w)
  - [Graph-Vit/MLP-Mixer-ICML2023](https://mp.weixin.qq.com/s/3NmnJ6Cmw834Wz55HenFfw)
  - [CF-Vit-AAAI2023](https://mp.weixin.qq.com/s/J_wDSANS2DselnIUM5kR7w)
  - [Mask2former](https://mp.weixin.qq.com/s/apb_oXHoymAmGZCRXU6MQQ)
