- 论文
  - [A Survey on Generative Diffusion Model](https://arxiv.org/abs/2209.02646)
  - [Self-Supervised Multimodal Learning: A Survey](https://arxiv.org/abs/2304.01008)
    
    

  - Sound and Visual Representation Learning with Multiple Pretraining Tasks Arxiv2022 [Paper](https://arxiv.org/abs/2201.01046) [Note](https://juejin.cn/post/7080724955414921247)

  - Interventional Contrastive Learning with Meta Semantic Regularizer ICML2022 [Paper](https://arxiv.org/abs/2206.14702) [Note](https://juejin.cn/post/7183909795198402619)

  - MetAug: Contrastive Learning via Meta Feature Augmentation ICML2022 [Paper](https://arxiv.org/abs/2203.05119) [Note](https://juejin.cn/post/7182797568681148477)

  - Automated Self-Supervised Learning for Graphs ICLR2022 [Paper](https://arxiv.org/abs/2106.05470) [Note](https://juejin.cn/post/7081164839837499399)

  - Neighbor Contrastive Learning on Learnable Graph Augmentation AAAI2023 [Paper](https://arxiv.org/abs/2301.01404) [Note](https://juejin.cn/post/7222174980531191845)
  - [[ALBEF][NeurIPS 21]Align before Fuse: Vision and Language Representation Learning with Momentum Distillation](https://arxiv.org/abs/2107.07651)
  - [[Rethink Trm][ICML 21]Synthesizer: Rethinking Self-Attention in Transformer Models](https://arxiv.org/abs/2005.00743)

  - [[FFCLIP][NeurIPS 22]One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations](https://arxiv.org/abs/2210.07883)
  - [[CFViT][AAAI 22]CF-ViT: A General Coarse-to-Fine Method for Vision Transformer](https://arxiv.org/abs/2203.03821)
  - [[SPACH][AAAI 22]When Shift Operation Meets Vision Transformer: An Extremely Simple Alternative to Attention Mechanism](https://arxiv.org/abs/2201.10801)
  - [[CLCLEF][ACL 22]GL-CLEF: A Global–Local Contrastive Learning Framework for Cross-lingual Spoken Language Understanding](https://arxiv.org/abs/2204.08325)
  - [[MixSKD][ECCV 22]MixSKD: Self-Knowledge Distillation from Mixup for Image Recognition](https://arxiv.org/abs/2208.05768)
  - [[IPMT][NeurIPS 22]Intermediate Prototype Mining Transformer for Few-Shot Semantic Segmentation](https://arxiv.org/abs/2210.06780)
  - [[Trm后剪枝][NeurIPS 22]A Fast Post-Training Pruning Framework for Transformers](https://arxiv.org/abs/2204.09656)
  - [[DataDistill][NeurIPS 22]Dataset Distillation via Factorization](https://arxiv.org/abs/2210.16774)

  - [[BLIP][Arxiv 23]InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning](https://arxiv.org/abs/2305.06500)
  - [[IRB][Arxiv 23]Rethinking Mobile Block for Efficient Neural Models](https://arxiv.org/abs/2301.01146)
  - [[VideoMAE][Arxiv 23]VideoMAE V2: Scaling Video Masked Autoencoders with Dual Masking](https://arxiv.org/abs/2303.16727)
  - [[DETR][CVPR 23]Siamese DETR](https://arxiv.org/abs/2303.18144)
  - [[DataGenerate][Arxiv 23]Regeneration Learning: A Learning Paradigm for Data Generation](https://arxiv.org/abs/2301.08846)
  - [[Dropout][ICML 23]Dropout Reduces Underfitting](https://arxiv.org/abs/2303.01500)
  - [[HomoDitill][Arxiv 23]HOMODISTIL: HOMOTOPIC TASK-AGNOSTIC DISTIL- LATION OF PRE-TRAINED TRANSFORMERS](https://arxiv.org/abs/2302.09632)
  - [[GWAE][ICLR 23]GROMOV-WASSERSTEIN AUTOENCODERS](https://arxiv.org/abs/2209.07007)
  - [[MLPinit][ICLR 23]MLPINIT: EMBARRASSINGLY SIMPLE GNN TRAIN- ING ACCELERATION WITH MLP INITIALIZATION](https://arxiv.org/abs/2210.00102)
  - [[Distill GNN][WSDM  23]Learning to Distill Graph Neural Networks](http://shichuan.org/doc/144.pdf)
  - [[Unidiffuser][ICML 23]One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale](https://arxiv.org/abs/2303.06555)

- Mixup
  - [[MixUP][ICLR 18]mixup: BEYOND EMPIRICAL RISK MINIMIZATION](https://arxiv.org/abs/1710.09412)
  - [[CutMix][ICCV 19]CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features](https://arxiv.org/abs/1905.04899)
  - [[MainfoldMixup][ICML 19]Manifold Mixup: Better Representations by Interpolating Hidden States](https://arxiv.org/abs/1806.05236)
  - [[CoMixup][ICLR 21]Co-Mixup: Saliency Guided Joint Mixup with Supermodular Diversity](https://arxiv.org/abs/2102.03065)
  - [[SaliencyMix][ICLR 21]SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization](https://arxiv.org/abs/2006.01791)
  - [[StyleMix][CVPR 21]StyleMix: Separating Content and Style for Enhanced Data Augmentation](https://openaccess.thecvf.com/content/CVPR2021/papers/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.pdf)
  - [[SuperMix][CVPR 21]SuperMix: Supervising the Mixing Data Augmentation](https://arxiv.org/abs/2003.05034)
  - [[AlignMixup][CVPR 22]AlignMix: Improving representation by interpolating aligned features](https://arxiv.org/abs/2103.15375)
  - [[TokenMixup][NeurIPS 22]TokenMixup: Efficient Attention-guided Token-level Data Augmentation for Transformers](https://arxiv.org/abs/2210.07562)
    
- 解读
  - [2022-top10自监督论文](https://mp.weixin.qq.com/s/AQIWt4deRGnRw3E6msRrig)
  - [IPMT-NeurIPS2022](https://mp.weixin.qq.com/s/y9jKTWi6NTNe_-IhaxE6Mg)
  - [VideMAE-NeurIPS2022](https://mp.weixin.qq.com/s/vrRrOFWHYWbjvFDvt5Bu7w)
  - [Graph-Vit/MLP-Mixer-ICML2023](https://mp.weixin.qq.com/s/3NmnJ6Cmw834Wz55HenFfw)
  - [CF-Vit-AAAI2023](https://mp.weixin.qq.com/s/J_wDSANS2DselnIUM5kR7w)
  - [Mask2former](https://mp.weixin.qq.com/s/apb_oXHoymAmGZCRXU6MQQ)
