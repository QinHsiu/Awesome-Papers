- [[vits][ICML 21]Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech](https://arxiv.org/abs/2106.06103)
- [[VStyclone][ELSEVIER 22]VStyclone: Real-time Chinese voice style clone](https://pdf.sciencedirectassets.com/271419/1-s2.0-S0045790622X00098/1-s2.0-S0045790622007492/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAIaCXVzLWVhc3QtMSJIMEYCIQCFqKhWvUFxM768pkSFqD9j1eiGwsTqy%2BCC5u4zAlaRnwIhAI9ARB6dszu7gbnI9zlLKuY0m5eq%2BbC80rDWzp%2FOwR0tKrIFCFoQBRoMMDU5MDAzNTQ2ODY1Igx3PGyrWVQ03U88KH8qjwWn0ECtxWM084nYR2Rhy9VpL557ZrdISdqwKSgaTO7mqvNNezQ%2BKwkWgPwoJLR%2FOhqOGtk8nCv5ewkY%2BVt%2FWiLOMe%2F3icSx2vmGsjqiN2xuM2KO0kQ8gWGyo3hweRviBEbfZm%2B2jReiftu3eqLJVoH95LOY9F4ljIQWvWM%2FPqOFfSmOve5Cyb3aUxItjbUiB7ZOKKVbBmHWH2lSaY7n5tDl14p84xDpNDX9wDTzq8G97sOCkM%2FMckNsqQlfkwoegqWiRqbJxJ6jxFXftMKLFAqCzhGrUHyC%2F%2BSYPbzVTyKqW7TUuYlUA129jT1j19%2BVZu0ZEsUUhNgu2PvEF8OARdWnGXFC5boJF9ugmnV%2B89yNuOvfMOy5UiPf7o4aOAScBbRILa5Q7CE%2BSugbevb2fIY4uN3rQ3ABePPJf3xaosvQ5cYSLsOUJJ6%2BWPEoybWHOdBXHOXpVgZ5eIjIkFWTxEL5aMXc0M0TFYv16w9VFUJtqFbFQ3dqSQr%2Bm%2FBVNIGGpx2vOByBFIiwGt5iVGP%2F9FHfZG4X%2B9H1TtglkoIrRk0My1HnVoc1MFRl9567QckYRdglQ9YtOkfPEj6iJ9m9mtERhvhFmmZDH8y45f4j6OU%2F1G2k9blUWrrGPjy%2B2Zyz4Rn1VR0TLu1xJ1cspYvnCu4EOsjVmp0Vg1KlDrVqB0GJS6VYPRLeSM%2BXzgKKbMs%2BRD2zyYlZ5HazKrxYtKyd4azeQ0Oezy%2F%2Fv0Pe0TLNsGHAJhy3IQb16%2FDwbt%2FxpB83c5bvPFPyHumd30ZNLlKxtop9rCNL76xrOb8UB5mFqtfCw3KqFOhB343DGL%2BWjmz596XyyYcQgh13XSM7BPQZh2jZOzDyGon3E1NJiuFq7vG0MJfytaQGOrABcw2gePy868q1vGFpMrJSEW1N3wRPT22SjnCu%2BR0uTUC0ph25FRDL4%2BrfKO7CDqgp6lO%2FFXu0KimTdPjfMj2VQc%2B2FK%2Bc4nohHE30MNalXsw%2FquNz04nHwuqUSGLFoPaQZtLskcXY1lPSfq1OS4xE3oqEe4A%2BdahkFti0OHMMSg0FLnfPZ1iyTy0a13wtTEbTeEqKxlr0edXkLWo01ZqL2ZS2yyv%2F5o7YM%2FL20s4ujm8%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230617T101808Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYQJHHIEMJ%2F20230617%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=ab4d377fb7239f3fb1a62f2de39880838233436f7613bd9b59efce3db4d13601&hash=27dd52b1752974aacfa549085c5f4559df4533dea1a8bfd80f2f7d3123bb1eb4&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0045790622007492&tid=spdf-2dec1e5b-169d-4f92-af7f-2843d2e22174&sid=4e0c9953229119485748822513f9113f60bdgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=190855035d0f5b06085e53&rr=7d8a8bf94ce56464&cc=cn)
- [[data2vec][ICML 22]data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language](https://arxiv.org/abs/2202.03555)
- [[MQTTS][AAAI 23]A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech](https://arxiv.org/abs/2302.04215)
- [[VoiceBox][Arxiv 23]Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://arxiv.org/abs/2306.15687)
- [[MusicGen][Arxiv 23]Simple and Controllable Music Generation](https://arxiv.org/abs/2306.05284)
- [[AudioPaLM][Arxiv 23]AudioPaLM: A Large Language Model That Can Speak and Listen](https://arxiv.org/pdf/2306.12925.pdf)
- Zero Shot
  - [[PromptTTS][Arxiv 22]PromptTTS: Controllable Text-to-Speech with Text Descriptions](https://arxiv.org/abs/2211.12171)
  - [[WaveGAN][InterSpeech 22]Glow-WaveGAN 2: High-quality Zero-shot Text-to-speech Synthesis and Any-to-any Voice Conversion](https://arxiv.org/abs/2207.01832)
  - [[BigVGAN][ICLR 23]BIGVGAN: A UNIVERSAL NEURAL VOCODER WITH LARGE-SCALE TRAINING](https://arxiv.org/abs/2206.04658)
  - [[VALLE][Arxiv 23]Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers](https://arxiv.org/abs/2301.02111)
  - [[Framework][Arxiv 23]Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining](https://arxiv.org/abs/2301.12596)
- One Shot
  - [[StyleTTS-VC][STL 22]STYLETTS-VC: ONE-SHOT VOICE CONVERSION BY KNOWLEDGE TRANSFER FROM STYLE-BASED TTS MODELS](https://arxiv.org/abs/2212.14227)
  - [[MFC-StyleVC][InterSpeech 23]DELIVERING SPEAKING STYLE IN LOW-RESOURCE VOICE CONVERSION WITH MULTI-FACTOR CONSTRAINTS](https://arxiv.org/pdf/2211.08857.pdf)
- Few Shot
  - [[HierSpeech][NeurIPS 22]HierSpeech: Bridging the Gap between Text and Speech by Hierarchical Variational Inference using Self-supervised Representations for Speech Synthesis](https://openreview.net/pdf?id=awdyRVnfQKX)
  - [[DSPGAN][ICASSP 23]DSPGAN: A GAN-BASED UNIVERSAL VOCODER FOR HIGH-FIDELITY TTS BY TIME-FREQUENCY DOMAIN SUPERVISION FROM DSP](https://arxiv.org/abs/2211.01087)
- [vits](https://github.com/QinHsiu/Awesome-Papers/blob/main/TTS/vits.md)

- 解读
  - [薛定谔桥构建语音合成](https://mp.weixin.qq.com/s/0ualxQR6QW-AJkh76dIdgg)
